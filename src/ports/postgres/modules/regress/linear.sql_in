/* ----------------------------------------------------------------------- *//** 
 *
 * @file linear.sql_in
 *
 * @brief SQL functions for linear regression
 * @date January 2011
 *
 * @sa For a brief introduction to linear regression, see the module
 *     description \ref grp_linreg.
 *
 *//* ----------------------------------------------------------------------- */
 
/**
@addtogroup grp_linreg

@about

Linear regression refers to a stochastic model, in which the conditional mean
of the dependent variable (usually denoted $y$) is an affine function of the
vector of independent variables (usually denoted \f$ \boldsymbol x \f$):
\f[
    E[y \mid \boldsymbol x] = \boldsymbol c^T \boldsymbol x
\f]
for some unknown vector of coefficients \f$ \boldsymbol c \f$.

We fit the model with the ordinary-least-squares method. That is, the vector of
regression coefficients \f$ \boldsymbol c \f$ is estimated as:
\f[
    \boldsymbol c = (X^T X)^+ X^T \boldsymbol y = X^+ \boldsymbol y
\f]
where
- $X$ is the design matrix with $k$ columns and $n$ rows, containing all
  observed vectors of independent variables \f$ \boldsymbol x_i \f$ as rows
- $X^T$ denotes the transpose of $X$
- $X^+$ dentoes the pseudo-inverse of $X$.
Note: The identity \f$ X^+ = (X^T X)^+ X^T \f$ holds for all matrices $X$. A
proof can be found, e.g., at:
http://en.wikipedia.org/wiki/Proofs_involving_the_Moore%2DPenrose_pseudoinverse

Computing the <b>total sum of squares</b> $TSS$, the <b>explained
sum of squares</b> $ESS$ (also called the regression sum of
squares), and the <b>residual sum of squares</b> $RSS$ (also called sum of
squared residuals or sum of squared errors of prediction) is
done according to the following formulas:
\f[\begin{align*}
    ESS & = \boldsymbol y^T X \boldsymbol c
        -   \frac{ \| y \|_1^2 }{n} \\
    TSS & = \sum_{i=1}^k y_i^2
        -   \frac{ \| y \|_1^2 }{n} \\
    R^2 & = \frac{ESS}{TSS}
\end{align*}\f]
Note: The last equality follows from the definition
\f$ R^2 = 1 - \frac{RSS}{TSS} \f$ and the fact that for linear regression
$TSS = RSS + ESS$. A proof of the latter can be found, e.g., at:
http://en.wikipedia.org/wiki/Sum_of_squares

We estimate the variance
\f$ Var[y - \boldsymbol c^T \boldsymbol x \mid \boldsymbol x] \f$ as
\f[
    \sigma^2 = \frac{RSS}{n - k}
\f]
and compute the t-statistic for coefficient $i$ as
\f[
    t_i = \frac{c_i}{\sqrt{\sigma^2 \cdot \left( (X^T X)^{-1} \right)_{ii} }}
\f]

The $p$-value for coefficient $i$ gives the probability that the null hypothesis
($c_i = 0$) is false, i.e., the probability that $c_i$ differs significantly
from 0. Letting \f$ F_\nu \f$ denote the cumulative density function of
student-t with \f$ \nu \f$ degrees of freedom, the $p$-value for coefficient $i$
is therefore
\f[
    p_i = P(|T| \geq |t_i|) = 2 \cdot (1 - F_{n - k}( |t_i| ))
\f]
where $T$ is a student-t distributed random variable with mean 0.

@prereq

Implemented in C for PostgreSQL/Greenplum.

@usage

-# The data set is expected to be of the following form:\n
   <tt>{TABLE|VIEW} <em>sourceName</em> ([...] <em>dependentVariable</em>
   DOUBLE PRECISION, <em>independentVariables</em> DOUBLE PRECISION[],
   [...])</tt>  
-# Run the linear regression by:\n
   <tt>SELECT \ref mregr_coef(float8,float8[]) "mregr_coef"(<em>dependentVariable</em>,
   <em>independentVariables</em>) FROM <em>sourceName</em></tt>\n
   Note: In order to model an intercept, set one coordinate in the
   <tt>independentVariables</tt> array to 1. (See below for an example.)
   \n
-# The coefficient of determination (also denoted $R^2$), the vector of
   t-statistics, and the vector of p-values can be determined likewise by
   mregr_r2(), mregr_tstats(), mregr_pvalues().

@examp

The following examples is taken from
http://www.stat.columbia.edu/~martin/W2110/SAS_7.pdf.

@verbatim
# select * from houses;
 id | tax  | bedroom | bath | price  | size |  lot  
----+------+---------+------+--------+------+-------
  1 |  590 |       2 |    1 |  50000 |  770 | 22100
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000
(15 rows)

# select mregr_coef(price, array[1, bedroom, bath, size])::REAL[] from houses;
             mregr_coef             
------------------------------------
 {27923.4,-35524.8,2269.34,130.794}
(1 row)

# select mregr_r2(price, array[1, bedroom, bath, size])::REAL from houses;
 mregr_r2 
----------
 0.745374
(1 row)

# select mregr_tstats(price, array[1, bedroom, bath, size])::REAL[] from houses;
             mregr_tstats             
--------------------------------------
 {0.495919,-1.41891,0.102183,3.61223}
(1 row)

# select mregr_pvalues(price, array[1, bedroom, bath, size])::REAL[] from houses;
              mregr_pvalues              
-----------------------------------------
 {0.629711,0.183633,0.920451,0.00408159}
(1 row)
@endverbatim

@sa file regression.sql_in (documenting the SQL functions)

@internal
@sa file regress.c (documenting the implementation in C), function
    float8_mregr_compute() (documenting the formulas used for coefficients,
    $R^2$, t-statistics, and p-values, implemented in C)
@endinternal

@literature

[1] Cosma Shalizi: Statistics 36-350: Data Mining, Lecture Notes, 21 October
    2009, http://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf

*/

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.linregr_transition(
    state DOUBLE PRECISION[],
    y DOUBLE PRECISION,
    x DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME'
LANGUAGE C
IMMUTABLE STRICT;


CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.linregr_combine(
    state1 DOUBLE PRECISION[],
    state2 DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME'
LANGUAGE C
IMMUTABLE STRICT;


-- Final functions

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.linregr_coef(
    state DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME'
LANGUAGE C IMMUTABLE STRICT;


CREATE FUNCTION MADLIB_SCHEMA.linregr_r2(
    state DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION
AS 'MODULE_PATHNAME'
LANGUAGE C IMMUTABLE STRICT;


CREATE FUNCTION MADLIB_SCHEMA.linregr_tstats(
    state DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME'
LANGUAGE C IMMUTABLE STRICT;


CREATE FUNCTION MADLIB_SCHEMA.linregr_pvalues(
    state DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME'
LANGUAGE C IMMUTABLE STRICT;


/**
 * @brief Compute multi-linear regression coefficients.
 *
 * To include an intercept in the model, set one coordinate in the
 * <tt>independentVariables</tt> array to 1.
 *
 * @return Array of coefficients, which has the same length as the array of
 *      independent variables.
 *
 * @examp <tt>SELECT mregr_coef(y, [1, x1, x2]) FROM data;</tt>
 */
CREATE AGGREGATE MADLIB_SCHEMA.linregr_coef(
    /*+ "dependentVariable" */ DOUBLE PRECISION,
    /*+ "independentVariables" */ DOUBLE PRECISION[]) (
    
    SFUNC=MADLIB_SCHEMA.linregr_transition,
    STYPE=float8[],
    FINALFUNC=MADLIB_SCHEMA.linregr_coef_final,
    m4_ifdef(`GREENPLUM',`prefunc=MADLIB_SCHEMA.linregr_merge_states,')
    INITCOND='{0,0,0,0,0}'
);

/**
 * @brief Compute the coefficient of determination, $R^2$.
 */
CREATE AGGREGATE MADLIB_SCHEMA.linregr_r2(
    /*+ "dependentVariable" */ DOUBLE PRECISION,
    /*+ "independentVariables" */ DOUBLE PRECISION[]) (
    
    SFUNC=MADLIB_SCHEMA.linregr_transition,
    STYPE=float8[],
    FINALFUNC=MADLIB_SCHEMA.linregr_r2_final,
    m4_ifdef(`GREENPLUM',`prefunc=MADLIB_SCHEMA.linregr_merge_states,')
    INITCOND='{0,0,0,0,0}'
);

/**
 * @brief Compute the vector of t-statistics, for every coefficient.
 *
 * To include an intercept in the model, set one coordinate in the
 * independentVariables array to 1.
 * 
 * @param dependentVariable Dependent variable
 * @param independentVariables Array of independent variables
 * @return Array of t-statistics for each coefficient. The returned array has
 *      the same length as the array of independent variables.
 */
CREATE AGGREGATE MADLIB_SCHEMA.linregr_tstats(
    /*+ "dependentVariable" */ DOUBLE PRECISION,
    /*+ "independentVariables" */ DOUBLE PRECISION[]) (
    
    SFUNC=MADLIB_SCHEMA.linregr_transition,
    STYPE=float8[],
    FINALFUNC=MADLIB_SCHEMA.linregr_tstats_final,
    m4_ifdef(`GREENPLUM',`prefunc=MADLIB_SCHEMA.linregr_merge_states,')
    INITCOND='{0,0,0,0,0}'
);

/**
 * @brief Compute the vector of p-values, for every coefficient.
 *
 * @param dependentVariable Dependent variable
 * @param independentVariables Array of independent variables
 * @return Array of p-values for each coefficient. The returned array has
 *      the same length as the array of independent variables.
 */
CREATE AGGREGATE MADLIB_SCHEMA.linregr_pvalues(
    /*+ "dependentVariable" */ DOUBLE PRECISION,
    /*+ "independentVariables" */ DOUBLE PRECISION[]) (
    
    SFUNC=MADLIB_SCHEMA.linregr_transition,
    STYPE=float8[],
    FINALFUNC=MADLIB_SCHEMA.linregr_pvalues_final,
    m4_ifdef(`GREENPLUM',`prefunc=MADLIB_SCHEMA.linregr_merge_states,')
    INITCOND='{0,0,0,0,0}'
);
