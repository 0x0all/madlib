About:
------

    This module implements the class of online learning with kernels 
    algorithms described in

      Jyrki Kivinen, Alexander J. Smola and Robert C. Williamson, 
      Online Learning with Kernels, IEEE Transactions on Signal Processing, 
      52(8), 2165-2176, 2004.

    The implementation follows the original description in the Kivinen et al 
    paper faithfully, except that we only update the support vector model 
    when we make a significant error. The original algorithms update the 
    support vector model at every step, even when no error was made, in the 
    name of regularisation. For practical purposes, and this is verified 
    empirically to a certain degree, updating only when necessary is both 
    faster and better from a learning point of view.

    Methods for classification, regression and novelty detection are 
    available. Multiple instances of the algorithms can be executed 
    in parallel on different subsets of the training data. The resultant
    support vector models can then be combined using standard techniques
    like averaging or majority voting.

    Training data points are accessed via a table or a view. The support
    vector models can also be stored in tables for fast execution.

To Do:
------

    - Add support for sparse vectors (now it's only array of float8s).

Prerequisites:
--------------

    None at this point. Will need to install the Greenplum sparse vector 
    SVEC datatype eventually.


Installation:
-------------

    1) Create database objects:
    
        psql -f online_sv.sql -d <database>


Preparation of the Input:
-------------------------

    1) Insert the training data into the table sv_train_data, which has
       the following structure:
    
        (
    		id 		INT,  	    -- point ID
    		ind		FLOAT8[],   -- data point
		label		FLOAT8	    -- label of data point
    	)
    
        Note!:  You can use the "generateData" function to populate the 
		sv_train_data table with randomly generated data labelled
		with a simple target function. For example,
                   select generateData(10000,5);
                produces ten thousand five-dimensional data points.
    

Execution (in-database):
------------------------

    Example usage for regression:
 
       SQL> select generateRegData(1000, 5);
       SQL> insert into sv_results (select 'myexp', online_sv_reg_agg(ind, label) from sv_train_data);
       SQL> select storeModel('myexp');
       SQL> select svs_predict('myexp', '{1,2,4,20,10}');
   
    To learn multiple support vector models, replace the above by 

       SQL> insert into sv_results (select 'myexp' || gp_segment_id, online_sv_reg_agg(ind, label) from sv_train_data group by gp_segment_id);
       SQL> select storeModel('myexp', n); -- n is the number of segments
       SQL> select * from svs_predict_combo('myexp', n, '{1,2,4,20,10}');

    Example usage for classification:
 
       SQL> select generateClData(2000, 5);
       SQL> insert into sv_results (select 'myexpc', online_sv_cl_agg(ind, label) from sv_train_data);
       SQL> select storeModel('myexpc');
       SQL> select svs_predict('myexpc', '{10,-2,4,20,10}');
   
    To learn multiple support vector models, replace the above by 

       SQL> insert into sv_results (select 'myexpc' || gp_segment_id, online_sv_cl_agg(ind, label) from sv_train_data group by gp_segment_id);
       SQL> select storeModel('myexpc', n); -- n is the number of segments
       SQL> select * from svs_predict_combo('myexpc', n, '{10,-2,4,20,10}');


Timing Tests:
-------------
#instances | #dim | seconds |
   10,000  |  5   |     52  |
  100,000  |  5   |    500  |
  200,000  |  5   |   1261  |
  500,000  |  5   |   4050  |
 1000,000  |  5   |  11956  |

    